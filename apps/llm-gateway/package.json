{
  "name": "@phalanx/llm-gateway",
  "version": "0.1.0",
  "private": true,
  "type": "module",
  "main": "./dist/index.js",
  "scripts": {
    "build": "tsc",
    "dev": "tsx watch src/index.ts",
    "start": "node dist/index.js",
    "test": "vitest run",
    "test:watch": "vitest",
    "lint": "eslint src",
    "typecheck": "tsc --noEmit",
    "clean": "rm -rf dist"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.17.0",
    "@fastify/cors": "^8.5.0",
    "@fastify/sensible": "^5.5.0",
    "fastify-type-provider-zod": "^2.0.0",
    "@opentelemetry/api": "^1.7.0",
    "@opentelemetry/sdk-node": "^0.45.1",
    "@opentelemetry/auto-instrumentations-node": "^0.39.4",
    "@phalanx/schemas": "workspace:*",
    "@phalanx/shared": "workspace:*",
    "fastify": "^4.25.2",
    "ioredis": "^5.3.2",
    "ollama": "^0.5.0",
    "openai": "^4.24.1",
    "prom-client": "^15.1.0",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/node": "^20.10.0",
    "tsx": "^4.7.0",
    "typescript": "^5.3.3",
    "vitest": "^1.0.4"
  }
}
