<<<<<<< HEAD
# phalanx
=======
# Phalanx - Self-Hosted LLM Automation Platform

> An open-source, enterprise-ready automation platform that empowers developers to build and execute complex AI-driven workflows using self-hosted LLMs, with extensive tool execution capabilities including shell commands and Model Context Protocol (MCP) servers.

## ðŸŒŸ Key Features

- ðŸ  **Self-Hosted LLM Support**: Run models locally (Ollama, vLLM, LocalAI) or on private infrastructure
- ðŸ¤– **Advanced Automation**: Multi-step workflows with parallel tool execution and state management
- ðŸ”§ **Binary Execution**: Direct shell command and binary execution with security controls
- ðŸ”Œ **MCP Integration**: Full Model Context Protocol support for extensible tool ecosystems
- ðŸŽ¯ **Agent Orchestration**: Complex agent-to-agent communication and task delegation
- ðŸ”’ **Enterprise Security**: Policy-based execution control, sandboxing, and audit trails

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Interfaces: CLI/TUI â€¢ Web UI â€¢ IDE Extensions          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway: AuthN (OIDC) â€¢ AuthZ (RBAC) â€¢ Rate Limiting    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Core Services:                                              â”‚
â”‚  â€¢ LLM Gateway        â€¢ Tool Runner                         â”‚
â”‚  â€¢ Workflow Engine    â€¢ MCP Client Manager                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ Project Structure

```
phalanx/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api-gateway/       # API Gateway with OIDC/RBAC
â”‚   â”œâ”€â”€ llm-gateway/       # LLM provider abstraction
â”‚   â”œâ”€â”€ workflow-engine/   # DAG workflow orchestration
â”‚   â”œâ”€â”€ tool-runner/       # Tool execution with sandboxing
â”‚   â”œâ”€â”€ mcp-manager/       # MCP server lifecycle management
â”‚   â”œâ”€â”€ web/               # Web UI (Next.js)
â”‚   â””â”€â”€ cli/               # CLI/TUI interface
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ shared/            # Shared utilities (logger, errors)
â”‚   â”œâ”€â”€ schemas/           # Zod schemas and types
â”‚   â”œâ”€â”€ sdk-js/            # TypeScript SDK
â”‚   â””â”€â”€ sdk-py/            # Python SDK
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ compose/           # Docker Compose for local dev
â”‚   â”œâ”€â”€ helm/              # Kubernetes Helm charts
â”‚   â””â”€â”€ migrations/        # Database migrations
â”œâ”€â”€ examples/              # Example workflows and tools
â””â”€â”€ e2e/                   # End-to-end tests
```

## ðŸš€ Quick Start

### Prerequisites

- Node.js 20+
- pnpm 8+
- Docker & Docker Compose
- PostgreSQL 16+ (for production)

### Local Development Setup

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/phalanx.git
cd phalanx
```

2. **Install dependencies**

```bash
pnpm install
```

3. **Start local infrastructure**

```bash
docker compose -f infra/compose/dev.yml up -d
```

This starts:
- PostgreSQL (port 5432)
- Redis (port 6379)
- MinIO (port 9000, console 9001)
- Jaeger (UI port 16686)
- Ollama (port 11434)
- Prometheus (port 9090)
- Grafana (port 3000, admin/admin)

4. **Run database migrations**

```bash
pnpm run migrate
```

5. **Start development servers**

```bash
pnpm run dev
```

6. **Pull a local LLM model (optional)**

```bash
docker exec -it phalanx-ollama ollama pull llama3.1:8b
```

### Configuration

Create a configuration file at `~/.config/llm-automation/config.json`:

```json
{
  "providers": {
    "default": "ollama/llama3.1:8b",
    "aliases": {
      "fast": "ollama/llama3.1:8b",
      "powerful": "anthropic/claude-3.5"
    }
  },
  "sandbox": {
    "executor": "oci",
    "limits": {
      "cpu": 1,
      "mem": "1Gi",
      "timeoutSec": 120
    }
  }
}
```

## ðŸ“– Documentation

- [Architecture Guide](./docs/architecture.md)
- [API Reference](./docs/api.md)
- [Configuration](./docs/configuration.md)
- [Security Model](./docs/security.md)
- [Development Guide](./docs/development.md)

## ðŸ§ª Testing

```bash
# Run all tests
pnpm run test

# Run tests in watch mode
pnpm run test:watch

# Run tests with coverage
pnpm run test -- --coverage

# Run linting
pnpm run lint

# Type check
pnpm run typecheck
```

## ðŸ—ï¸ Building

```bash
# Build all packages
pnpm run build

# Build specific package
pnpm --filter @phalanx/api-gateway build
```

## ðŸ³ Docker

Build and run with Docker:

```bash
# Build all services
docker compose build

# Run production stack
docker compose up -d
```

## ðŸ“Š Monitoring

Access the following UIs when running locally:

- **Grafana**: http://localhost:3000 (admin/admin)
- **Jaeger**: http://localhost:16686
- **Prometheus**: http://localhost:9090
- **MinIO Console**: http://localhost:9001 (phalanx/phalanx123)

## ðŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `pnpm run test`
5. Commit: `git commit -m 'Add amazing feature'`
6. Push: `git push origin feature/amazing-feature`
7. Open a Pull Request

## ðŸ“‹ Roadmap

### M1: Foundation (Weeks 1-4) - Current

- [x] Monorepo scaffolding
- [x] Shared packages (schemas, utilities)
- [ ] API Gateway with OIDC/RBAC
- [ ] LLM Gateway (OpenAI, Anthropic, Ollama)
- [ ] Tool Runner with shell execution
- [ ] Basic workflow engine

### M2: Tooling & MCP (Weeks 5-8)

- [ ] MCP client manager
- [ ] Policy engine for tool execution
- [ ] Multi-turn workflow support
- [ ] CLI/TUI interface

### M3: Enterprise (Weeks 9-12)

- [ ] Advanced security (sandboxing, audit logs)
- [ ] Cost accounting & quotas
- [ ] Web UI for workflow management
- [ ] GitHub App integration

## ðŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](./LICENSE) file for details.

## ðŸ™ Acknowledgments

- Inspired by Google's Gemini CLI architecture
- Built on the [Model Context Protocol](https://modelcontextprotocol.io/)
- Powered by open-source LLMs and tools

## ðŸ“§ Contact

- GitHub Issues: [https://github.com/yourusername/phalanx/issues](https://github.com/yourusername/phalanx/issues)
- Discord: [Join our community](https://discord.gg/phalanx)

---

Made with â¤ï¸ by the Phalanx team
>>>>>>> 61ba0f0 (feat: initial project scaffolding for Phalanx platform)
